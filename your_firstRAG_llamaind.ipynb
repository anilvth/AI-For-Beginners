{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilvth/AI-For-Beginners/blob/main/your_firstRAG_llamaind.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_Ks9QAdQ5Ueq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b745fe9-e825-4b14-cfbe-2158515b609d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the OpenAI API key from Google Colab secrets\n",
        "openai.api_key = userdata.get('openai')\n",
        "print(openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-index"
      ],
      "metadata": {
        "id": "bTc0YUFK5htr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220d494c-ea79-4f5e-88fa-fe0a13995466"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.12/dist-packages (0.14.5)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.14.5)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.9.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.6.5)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.4)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (3.13.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.8.3)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (4.5.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.11.10)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.5->llama-index) (1.17.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.109.1)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.10.5)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<7,>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.1.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.5->llama-index) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.2)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.5->llama-index) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.5->llama-index) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"what is this document about\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGWBOUg36AIp",
        "outputId": "504d6699-6a7c-41da-ca57-4018722e90e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The document is about the author's experiences and reflections on his time as a student in both graduate school and art school, particularly focusing on his decision-making processes, academic pursuits, interactions with professors and fellow students, and his transition from one institution to another.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Load and index documents\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents=documents)\n",
        "\n",
        "# Query the index\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"who is mentioned about in document\")\n",
        "print(response)\n",
        "\n",
        "# End timer and print duration\n",
        "end_time = time.time()\n",
        "print(f\"\\nExecution Time: {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvU6WLaJ7pMR",
        "outputId": "c0be339e-03f8-4ad3-c896-621ac7f4ca7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trevor Blackwell, John Collison, Patrick Collison, Daniel Gackle, Ralph Hazell, Jessica Livingston, Robert Morris, and Harj Taggar are mentioned in the document.\n",
            "\n",
            "Execution Time: 3.92 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "# check if storage already exists\n",
        "PERSIST_DIR = \"./storage\"\n",
        "if not os.path.exists(PERSIST_DIR):\n",
        "    # load the documents and create the index\n",
        "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    # store it for later\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "else:\n",
        "    # load the existing index\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context)\n",
        "\n",
        "# Either way we can now query the index\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "retriever = VectorIndexRetriever(index=index, similarity_top_k=2)\n",
        "\n",
        "query_engine = RetrieverQueryEngine(retriever=retriever)\n",
        "\n",
        "response = query_engine.query(\"Who all mentioned in the doc?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnpYevQMlXhq",
        "outputId": "86fd8a02-6d49-4aa1-fea2-b2dff4c395e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reddit, Justin Kan, Emmett Shear, Aaron Swartz, Sam Altman, Julian, Robert, Jessica, Kevin Hale, Robert Morris, Trevor, and Sam Altman.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "# Start timer for index setup\n",
        "start_time = time.time()\n",
        "\n",
        "# check if storage already exists\n",
        "PERSIST_DIR = \"./storage\"\n",
        "if not os.path.exists(PERSIST_DIR):\n",
        "    # load the documents and create the index\n",
        "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    # store it for later\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "else:\n",
        "    # load the existing index\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context)\n",
        "\n",
        "setup_duration = time.time() - start_time\n",
        "print(f\"Index setup time: {setup_duration:.2f} seconds\")\n",
        "\n",
        "# Start timer for query\n",
        "query_start_time = time.time()\n",
        "\n",
        "# Prepare the query engine\n",
        "retriever = VectorIndexRetriever(index=index, similarity_top_k=2)\n",
        "query_engine = RetrieverQueryEngine(retriever=retriever)\n",
        "\n",
        "# Execute query\n",
        "response = query_engine.query(\"Who all mentioned in the doc?\")\n",
        "print(response)\n",
        "\n",
        "query_duration = time.time() - query_start_time\n",
        "print(f\"Query time: {query_duration:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzWZZpsmmHV9",
        "outputId": "9f42c40b-bcba-45ac-8cf6-a35a1d285c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index setup time: 0.44 seconds\n",
            "Reddit, Justin Kan, Emmett Shear, Aaron Swartz, Sam Altman, Julian, Robert, Jessica, Kevin Hale, Robert Morris, Trevor, Sam Altman's mother.\n",
            "Query time: 1.08 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1nc07s-HtMR",
        "outputId": "e9cb9e3f-c1f8-41cb-8bfa-fbdd4d250e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.119.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.3)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "import os\n",
        "\n",
        "# Load documents and build the index\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents=documents)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Query function\n",
        "def query_document(query):\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)\n",
        "\n",
        "# Define app UI using Blocks\n",
        "def launch_interface():\n",
        "    with gr.Blocks(title=\"RAG Application Using LlamaIndex\") as demo:\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=150):\n",
        "                if os.path.exists(\"data/dds_logo.jpg\"):\n",
        "                    gr.Image(\n",
        "                        value=\"data/dds_logo.jpg\",\n",
        "                        show_label=False,\n",
        "                        container=False,\n",
        "                        scale=0.5\n",
        "                    )\n",
        "            with gr.Column(scale=4):\n",
        "                gr.Markdown(\n",
        "                    \"\"\"\n",
        "                    <div style='text-align: center;'>\n",
        "                        <h2>RAG Application with LlamaIndex</h2>\n",
        "                        <p>Ask questions based on your uploaded documents using Retrieval-Augmented Generation (RAG).</p>\n",
        "                    </div>\n",
        "                    \"\"\",\n",
        "                    elem_id=\"header\"\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                query_input = gr.Textbox(\n",
        "                    lines=2,\n",
        "                    placeholder=\"Type your question here...\",\n",
        "                    label=\"Your Query\"\n",
        "                )\n",
        "                submit_btn = gr.Button(\"Submit\")\n",
        "\n",
        "            with gr.Column():\n",
        "                response_output = gr.Textbox(\n",
        "                    lines=10,\n",
        "                    label=\"Response\"\n",
        "                )\n",
        "\n",
        "        submit_btn.click(query_document, inputs=query_input, outputs=response_output)\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    launch_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "JagFi6o3Hfda",
        "outputId": "23493561-94f7-48c1-b4c4-8dff59814f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/components/base.py:207: UserWarning: 'scale' value should be an integer. Using 0.5 will cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://711463e4429410af2d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://711463e4429410af2d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "import os\n",
        "\n",
        "# Load documents and build the index\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents=documents)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Query function\n",
        "def query_document(query):\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)\n",
        "\n",
        "# Define app UI using Blocks\n",
        "def launch_interface():\n",
        "    with gr.Blocks(title=\"RAG Application Using LlamaIndex\") as demo:\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1, min_width=200):\n",
        "                if os.path.exists(\"data/logo.png\"):\n",
        "                    gr.Image(\"data/logo.png\", label=\"Logo\", show_label=False)\n",
        "            with gr.Column(scale=4):\n",
        "                gr.Markdown(\n",
        "                    \"\"\"\n",
        "                    ## 📄 RAG Application with LlamaIndex\n",
        "                    Ask questions based on your uploaded documents using Retrieval-Augmented Generation (RAG).\n",
        "                    \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                query_input = gr.Textbox(\n",
        "                    lines=2,\n",
        "                    placeholder=\"Type your question here...\",\n",
        "                    label=\"Your Query\"\n",
        "                )\n",
        "                submit_btn = gr.Button(\"Submit\")\n",
        "\n",
        "            with gr.Column():\n",
        "                response_output = gr.Textbox(\n",
        "                    lines=10,\n",
        "                    label=\"Response\"\n",
        "                )\n",
        "\n",
        "        submit_btn.click(query_document, inputs=query_input, outputs=response_output)\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    launch_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "5HlFo_29IvfX",
        "outputId": "09914a1e-9108-495e-9e7f-71daceb16f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b56ff19ba7465355d3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b56ff19ba7465355d3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "import os\n",
        "\n",
        "# Load documents and build the index\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Define recommended questions\n",
        "recommended_questions = [\n",
        "    \"What does the Travel Infinity insurance cover for international travel?\",\n",
        "    \"What is considered an emergency in-patient treatment under this policy?\",\n",
        "    \"How are maternity expenses handled in the Travel Infinity plan?\",\n",
        "    \"What exclusions are listed in the Travel Infinity insurance policy?\",\n",
        "    \"What is the claim process for lost checked-in baggage?\"\n",
        "]\n",
        "\n",
        "# Query function\n",
        "def query_document(query):\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)\n",
        "\n",
        "# Interface with professional layout\n",
        "def launch_interface():\n",
        "    with gr.Blocks(title=\"RAG Application Using LlamaIndex\") as demo:\n",
        "        # Header Row: Logo + Recommended Questions\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                if os.path.exists(\"data/logo.png\"):\n",
        "                    gr.Image(value=\"data/logo.png\", show_label=False, container=False, scale=0.5)\n",
        "            with gr.Column(scale=4):\n",
        "                gr.Markdown(\n",
        "                    \"\"\"\n",
        "                    <div style='text-align: center;'>\n",
        "                        <h2>RAG Application with LlamaIndex</h2>\n",
        "                        <p>Ask questions based on your uploaded insurance documents.</p>\n",
        "                        <h4>📌 Recommended Questions:</h4>\n",
        "                        <ul>\n",
        "                            <li>What does the Travel Infinity insurance cover for international travel?</li>\n",
        "                            <li>What is considered an emergency in-patient treatment under this policy?</li>\n",
        "                            <li>How are maternity expenses handled in the Travel Infinity plan?</li>\n",
        "                            <li>What exclusions are listed in the Travel Infinity insurance policy?</li>\n",
        "                        </ul>\n",
        "                    </div>\n",
        "                    \"\"\",\n",
        "                    elem_id=\"header\"\n",
        "                )\n",
        "\n",
        "        # Interaction Row: Input and Output\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                query_input = gr.Textbox(\n",
        "                    lines=2,\n",
        "                    placeholder=\"Type your question here...\",\n",
        "                    label=\"Your Query\"\n",
        "                )\n",
        "                submit_btn = gr.Button(\"Submit\")\n",
        "            with gr.Column():\n",
        "                response_output = gr.Textbox(lines=10, label=\"Response\")\n",
        "\n",
        "        submit_btn.click(query_document, inputs=query_input, outputs=response_output)\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    launch_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "qfes14ZIKWKn",
        "outputId": "1ee40e21-279f-4287-bf5e-419ca4463bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/base.py:206: UserWarning: 'scale' value should be an integer. Using 0.5 will cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ebb9aadce4ee989848.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ebb9aadce4ee989848.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "import os\n",
        "\n",
        "# Load documents and build index\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents=documents)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Recommended questions based on document content\n",
        "recommended_questions = [\n",
        "    \"What is covered under Emergency In-patient medical treatment?\",\n",
        "    \"What is the meaning of pre-existing disease in the policy?\",\n",
        "    \"What are the exclusions for outpatient treatment?\",\n",
        "    \"What benefits are included in maternity coverage?\",\n",
        "    \"What is the process for trip cancellation claim?\",\n",
        "]\n",
        "\n",
        "# Query function\n",
        "def query_document(query):\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)\n",
        "\n",
        "# Dropdown handler\n",
        "def handle_dropdown_selection(selected_question):\n",
        "    return query_document(selected_question)\n",
        "\n",
        "# Gradio interface with two rows\n",
        "def launch_interface():\n",
        "    with gr.Blocks(title=\"RAG Application Using LlamaIndex\") as demo:\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                if os.path.exists(\"data/logo.png\"):\n",
        "                    gr.Image(\"data/logo.png\", show_label=False, scale=0.5, container=False)\n",
        "            with gr.Column(scale=4):\n",
        "                gr.Markdown(\n",
        "                    \"\"\"\n",
        "                    <div style='text-align: center;'>\n",
        "                        <h2>RAG Application with LlamaIndex</h2>\n",
        "                        <p>Ask questions about the documents. You can start with a suggested question or enter your own below.</p>\n",
        "                    </div>\n",
        "                    \"\"\",\n",
        "                    elem_id=\"header\"\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### 🔎 Recommended Questions\")\n",
        "                question_dropdown = gr.Dropdown(\n",
        "                    choices=recommended_questions,\n",
        "                    label=\"Choose a question\",\n",
        "                    interactive=True\n",
        "                )\n",
        "            with gr.Column():\n",
        "                rag_response = gr.Textbox(label=\"Response\", lines=10)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                user_query = gr.Textbox(label=\"Or type your own question\", placeholder=\"Enter your query...\")\n",
        "                submit_btn = gr.Button(\"Submit\")\n",
        "            with gr.Column():\n",
        "                manual_response = gr.Textbox(label=\"Response\", lines=10)\n",
        "\n",
        "        # Logic wiring\n",
        "        question_dropdown.change(handle_dropdown_selection, inputs=question_dropdown, outputs=rag_response)\n",
        "        submit_btn.click(query_document, inputs=user_query, outputs=manual_response)\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    launch_interface()\n"
      ],
      "metadata": {
        "id": "Gsv441BlLBtZ",
        "outputId": "bbb1b2c6-888d-43d4-f743-697ae5766f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/base.py:206: UserWarning: 'scale' value should be an integer. Using 0.5 will cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8c3c7f7d331a1fdb26.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8c3c7f7d331a1fdb26.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}